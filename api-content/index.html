{"posts":[{"title":"pdf预览的几种方法","content":"快速实现 pdf / image 预览 预览 pdf / image 后台要求增加一个 预览pdf和图片文件的功能，查了一下实现方法，网上首推 pdf.js，我瞎捣鼓了一下，很是发现了几种实现方式，都挺便捷的。 访问静态文件url 通过文件流 HTML标签+Base64 pdf.js 下面详细说明一下几种方式的特点，并附上代码，由于我是使用的 layui，故例子都是layui的实现，其他框架也是差不多的，核心思路不变。 访问静态文件url 顾名思义，这种方式是针对已有的静态资源，不需要后端将其转换为流。 使用注意事项： 依赖浏览器对图片和pdf的支持，通常浏览器会解析为预览或者下载。 可以被下载监听插件比如IDM监听拦截，如果有相关插件，需要禁用或者添加例外。 示例： // layui.layer layer.open({ title: &quot;预览&quot;, type: 2, // iframe层，content 为url area: ['1000px', '750px'], content: '../static/a.pdf' }); 通过文件流 比较适合动态的文件的访问，原理就是服务端将文件读取并写入到输出流中，前端读取流内容。 这种方式比较灵活，对文件没什么限制 使用注意事项： 依赖浏览器的支持,可能会解析成预览或下载， 可以被下载监听插件比如IDM监听拦截。 示例： // layui.layer layer.open({ title: &quot;预览&quot;, type: 2, // iframe层，content 为url area: ['1000px', '750px'], content: '${pageContext.request.contextPath }/preview.pdf', }); Java后端返回流示例： public void detail(HttpServletRequest request, HttpServletResponse response) { // 生成或读取文件到字节数组 byte[] bytes = xxx; // 写入到输出流中 try { response.getOutputStream().write(bytes); // 设置文件类型 response.setContentType(&quot;application/pdf;charset=UTF-8&quot;); } catch (IOException e) { log.error(&quot;&quot;,e); } } HTML标签 + Base64 这种情况适用于使用时，已经加载到了客户端的资源。 特点： 开发简单 吃客户端内存 只加载一次，能有效减少网络io，如果文件比较大，还能节省大量时间 示例： layer.open({ title: &quot;预览&quot;, type: 1, // 页面层， content支持文本和html area: ['1000px', '750px'], // image tag content: '&lt;img src=&quot;data:image/png;base64,' + data.base64 + '&quot;/&gt;', // pdf tag content: '&lt;embed src=&quot;data:application/pdf;base64,'+ data.base64 +'&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt;' }); *pdf.js 网上用这个的人比较多，pdf.js 支持新老版本浏览器，可以基于viewer.html进行修改定制。 由于需求与效率原因，没有尝试，如果以上三板斧不能满足需求，pdf.js应该是不错的。 附： (pdf.js 官方连接)[https://github.com/mozilla/pdf.js] ","link":"https://season8.github.io/post/pdf-yl/"},{"title":"分布式id生成器","content":"最近老项目升级到cloud，用到了 snowflake，苦于手动配置workerId，撸了个没用的轮子---基于配置中心的雪花ID 分布式 ID 之 SNOWFLAKE 说起分布式id，首推 SNOWFLAKE（雪花算法），它具有以下优势： 高效：性能好 分布式唯一：与DB无关，适应分布式应用 趋势递增：与时间相关，保持一定的时序性，但又不是绝对递增，可防止id泄漏业务增长信息。 缺点大概就是： 与时间相关，时间错乱可能会出现重复id，即时钟回拨问题。 多应用服务之间，可能会产生id碰撞，这个可以通过设置workerId来解决。 实际使用中，时钟回拨概率很低，比较麻烦的通常是多服务的workerId配置问题： 每一个应用的workerId都要不相同从而避免ID碰撞 多个应用之间workerId差异化配置难以集中管理 对于多实例的应用，可能除了workerId，其他配置都是相同的，但不得不想办法进行差异化配置、打包、发布。 何不将每一个实例使用的workerId记录到一个地方？既方便管理，又能避免重复。 注册中心正好可以解决这个问题。 快速实现 这小玩意儿咱设计简陋点，就包含三个主要功能： 注册id 注销id 自动加载 注册id 这里主要考虑两点： 如何保证服务之间区分 如何确保服务注册的id是唯一 如何保证服务之间区分 要能区分服务，即是要有唯一的服务标识， 我选取的标识是：数据中心+ip+应用标识 当然我也是可以用随机生成UUID就能保证唯一的服务标识，但使用上面这种有两个好处： 幂等性：每次启动生成的标识是不变的 可读性：能从配置中心直接看到每个服务的配置状况。 如何确保服务注册的id是唯一 要保证注册id唯一，只需要在注册前检查所有注册值，如果已注册就换一个就行了。 即： 但这还不够，假如两个应用贼有缘，同时启动，随到同一个id，同时检查 id 是否已使用并得到否定结果，然后两人就注册了同一个id！这就是一个典型的多线程一票多卖的问题，看来还是要用锁才行啊。 经过一番修改，它看起来是这样： 用分布式锁锁住id，将检查、注册这部分功能变成串行。 注销id 利用 @PreDestroy 注释一个destroy方法（名字不限哈） ，在服务中断（非 kill -9）时，调用该方法注销配置。 关于 @PreDestroy 原理 和 Spring Boot 应用中断，这个有空也得自说自话一下。 自动装载 配置越少、越简单，才能用的方便不是，不然要被同事吐槽啦（👴：虽然这功能挺鸡肋，但它配置丰富啊🐶） 总结了一下，得实现以下4个自动化： yaml配置得有提示。 能根据不同类型配置中心配置自动装载配置中心服务。 无需额外的@ComponentScan、@Import 或java配置，自动装载。 yaml配置得有提示。 使用 spring-boot-configuration-processor 生成 spring-configuration-metadata.json 文件 能根据不同类型配置中心配置自动装载配置中心服务。 使用@ConditionalOnProperty、@ConditionalOnClass 即可做到 无需额外的@ComponentScan、@Import 或java配置，自动装载。 创建 spring.factories 并打包即可 关于 Spring 自动装载 和 相关注解，emmm.. 下次再说道说道好了。 缺陷 不能响应强制中断，从而造成id抢占，如果此时该应用永久下线或者网络配置发生变化，就造成了id泄漏，产生无效的配置数据。 如果注册中心不可用时，将使用兜底的随机id方式，会有id碰撞风险。 项目地址 id-generators ","link":"https://season8.github.io/post/id-generators/"},{"title":"我爱花里胡哨--TranslucentTB","content":"😎炫酷好用不折腾，颜值党必备神器。 名称：TranslucentTB 官网：https://github.com/TranslucentTB/TranslucentTB 用途：让windows任务栏透明 获取途径：官网 或 Microsoft Store 效果： 此处只展示常规场景下的效果： ##设置： 一级菜单主要提供（自上往下）： 常规、 应用全屏、 打开开始菜单、 打开系统搜索、 打开时间轴（win+tab） 各场景时任务栏颜色变化 对应二级菜单可设置任务栏为：常规、透明、毛玻璃效果以及自定义颜色。 基本上常规设置为透明就很炫酷了，其他看自己喜好即可。 另外，一定要打开设置里的 Open at boot(随系统启动) 设置一次，基本不用管了。 多桌面、多屏支持情况 完美支持 多桌面(ALT+WIN+⬅️/➡️) 支持多显示屏，偶尔会出现扩展屏不生效的情况，解决办法是直接再打开（不需要退出）TranslucentTB，即可生效。 资源消耗： 对cpu和内存都很友好： ","link":"https://season8.github.io/post/translucenttb/"},{"title":"重新认识 ThreadPoolExecutor","content":"❓ 更深入的理解ThreadPoolExecutor原理，纠正想当然的理解误区 一个事故引发的拷问 或许这篇文章可以起名更惊悚一点，叫做：《不合理的线程池配置酿成的血案。。》。 事情要从一个造成生产事故的案例说起： 同事开发了一个kafka消费者程序，并发消费消息： 使用Semaphore控制每次并发处理m个消息 每一个消息处理后都会生成 n 个任务，为了加快单个消息的处理速率，子任务也采用了并发的方式执行（消息和子任务线程池是分开的） 外层消息处理等待所有子任务执行完成才算完成。 整个模型设计的目标很明确，那就是每次能并发处理m个消息，m*n个子任务，每组子任务全部执行完毕后才会开始下一组。 但真实的情况是，发布线上后，子任务线程池大面积触发Reject，导致消息处理几乎瘫痪，下游出现数据缺失以及高延迟。 在协同检查后，我也认为这个模型设计十分精确，不会存在子任务超量的情况。 问题复现 由于该模型在本地测试并没有触发异常，考虑到是数据量级的原因，我基于现有模型，缩放了任务量级和配置，简化出了以下模型并复现了问题： 假设有多个消费事件组，要求同时最多三个事件组异步消费，而每个事件组由3个子事件组成，子事件同样使用异步消费。 public static void main(String[] args) throws InterruptedException { // @1 创建外部消费组线程池，固定大小3，队列197，一共200个消费组 ThreadPoolExecutor outter = new ThreadPoolExecutor(3, 3, 30, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(197)); // @2 创建内部事件处理线程池，core=9，max=12 ，队列长度为1。 ThreadPoolExecutor inner = new ThreadPoolExecutor(9, 12, 30, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(1)); //2 for (int i = 0; i &lt; 200; i++) { int group = i; // @3 消费组异步处理，由于outter固定大小为3，首次只有三个消费组消费事件。 outter.execute(() -&gt; { System.out.println(&quot;开始第&quot; + group + &quot; 组消费&quot;); CountDownLatch countDownLatch = new CountDownLatch(3); for (int j = 0; j &lt; 3; j++) { int task = j; // @4 3个事件异步消费， inner.execute(() -&gt; { System.out.println(group + &quot;组消费数据:&quot; + task); countDownLatch.countDown(); }); } // @5 outter线程等待三个inner线程结束，当前组才消费完成 try { countDownLatch.await(3, TimeUnit.SECONDS); System.out.println(&quot;第&quot; + group + &quot; 消费完成&quot;); } catch (InterruptedException e) { e.printStackTrace(); } }); } } 实现该模型的基本策略： 利用CountDownLatch保证outter线程在对应的三个inner线程执行完之后才执行完毕，即：保证批次执行； 利用outter固定线程池=3，保证每次最多只有三个outter线程执行； 同理，inner每次只能有 3（outter执行数量）* 3（事件数量） = 9 个线程在执行。所以理论上，inner的max=12是用不上的，队列也用不上。 执行结果： ... Exception in thread &quot;pool-1-thread-1&quot; Exception in thread &quot;pool-1-thread-3&quot; Exception in thread &quot;pool-1-thread-2&quot; java.util.concurrent.RejectedExecutionException: Task com.review.string.Demo7$$Lambda$2/1186543288@67dad061 rejected from java.util.concurrent.ThreadPoolExecutor@67aa5a39[Running, pool size = 12, active threads = 3, queued tasks = 0, completed tasks = 14] ... 可发发现，子任务线程池容量竟然扩充到了12，达到了最大容量，按前面所想，子任务数量应该是控制在3*3=9个才对。 分析 猜测：countDownLatch没有控制住 假设实际执行的outter active数量 * 3 &gt; 实际inner active线程数，从而导致inner线程达到最大线程数。 这里countDownLatch数量配置都是对的，增加inner消费处理时间，发现在reject前，outter线程都是在组内inner全部执行完才完成，没有失控的迹象。 如果你的猜测是这个，我觉得你可以多多使用juc中的工具，这个模型中，countDownLatch和线程池的配合使用是没有问题的。 猜测：线程调度的问题 假设outter线程o1执行完，o2、o3还在执行，开始执行o4，此时如果o1组内的inner线程 i1、i2、i3至少一个还没有及时归还到线程池中，这样o4组消费就会创建新的线程使得线程数&gt;core,持续几轮，线程池撑满从而触发reject。 这个猜测并无根据，但依然可以验证一下: countDownLatch.await(); TimeUnit.SECONDS.sleep(1); // outter强制等待inner结束 执行，仍然reject,可以排除该猜想 猜想都没有实际根据且都可以被证伪，我突然有些恐慌，比起在小同事这里翻车，我发现我根本没有理解线程池这件事才是超恐怖的。 我此时所认知的线程池： 活跃线程数 &lt; corePoolSize 时，直接创建线程来执行任务。 活跃线程数 = corePoolSize 时，任务添加到队列，等待空闲线程处理。 队列满时，直接创建线程来执行任务。 活跃线程数 = maxPoolSize，继续添加任务，触发reject。 通过后续的研究，我才发现，这几条简短的概括，并不能说错误，但是因为简短，说明有些概念并不明确，或者很模糊，正是这种似是而非的认识，导致我对线程池的具体细节都是想当然。 终极武器，看源码实现： 直接从核心方法 execute 入手： public void execute(Runnable command) { ... int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // @1 if (addWorker(command, true)) // @2 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // @3 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // @4 reject(command); else if (workerCountOf(recheck) == 0) // @5 addWorker(null, false); } else if (!addWorker(command, false)) // @6 reject(command); } 这里主要有6个不太明确作用的方法，我们逐个分析： workerCountOf isRunning addWorker workQueue.offer(command) remove(command) reject(command) workerCountOf &amp; isRunning 了解这两个方法是ThreadPoolExecutor类的基本方法，我们直接看ThreadPoolExecutor的源码： public class ThreadPoolExecutor extends AbstractExecutorService { /** * The main pool control state, ctl, is an atomic integer packing two conceptual fields * workerCount, indicating the effective number of threads * runState, indicating whether running, shutting down etc * * 译：状态ctl是一个包装了两个概念字段原子整数: * workerCount 指示有效的线程数, * runState 指示是否运行，关闭等 * ... * * The workerCount is the number of workers that have been * permitted to start and not permitted to stop. The value may be * transiently different from the actual number of live threads, * for example when a ThreadFactory fails to create a thread when * asked, and when exiting threads are still performing * bookkeeping before terminating. The user-visible pool size is * reported as the current size of the workers set. * * 译：workerCount是【已被允许启动且未被允许停止】的worder(即线程)数量。 * 该值可能与实际的活动线程数暂时不同：线程池创建线程时失败但又未完全注销， * 此时workerCount 可能会小于线程池实际大小。 * * 【已被允许启动且未被允许停止】 先简单理解为存活线程比较好理解 * ... * * The runState provides the main lifecycle control, taking on values: * * RUNNING: Accept new tasks and process queued tasks * SHUTDOWN: Don't accept new tasks, but process queued tasks * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * TIDYING: All tasks have terminated, workerCount is zero, * the thread transitioning to state TIDYING * will run the terminated() hook method * TERMINATED: terminated() has completed * * 译：runState提供线程池生命周期的控制，有以下状态值： * RUNNING：可接受新任务，可处理队列中的任务 * SHUTDOWN：不接受新任务，但可以处理队列中的任务 * STOP：不接受新任务，不处理队列中任务，并中断处理中的任务 * TIDYING：所有任务都已终止，workerCount(存活的线程数量)为0,往该状态过渡的线程将执行terminated() * TERMINATED: terminated()方法结束，相当于TIDYING的终态。 * ... * * 后面还有部分注释，讲的是runState 各个状态之间转换条件，不作列出，有兴趣可自研 * / // 状态和线程数集合包装字段ctl。 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static int runStateOf(int c) { return c &amp; ~CAPACITY; } // 从 ctl 拆解出 runState private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 从 crl 拆解出 workerCount private static int ctlOf(int rs, int wc) { return rs | wc; } // 将 workerCount 和 runState 包装为 ctl ... private static boolean isRunning(int c) { return c &lt; SHUTDOWN;} // 当前线程池状态，是否处于Running状态 ctl包装和解析 runState 与 workCount 的算法并未理解，但并不影响理解其概念。 workerCountOf方法 ：获取存活线程数量 isRunning方法 ：判断线程池状态是否处于Running(Running状态时线程池可接受新任务) addWorker private boolean addWorker(Runnable firstTask, boolean core) { //...（略掉一些状态校验） int wc = workerCountOf(c); // 线程池实际容量（存活线程数量） if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // @1 判断是否达到容量上限 //...（略掉一些状态校验） w = new Worker(firstTask); // @1 根据任务创建Worker对象 final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); // @2 将worker对象添加到集合workers中 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); // @3 添加成功，启动worker内置线程 workerStarted = true; } } //... } addWorker在execute方法中有两处调用，区别是参数core传值不同，从源码可以看出是判断当前线程池容量上限是CorePoolSize还是MaxPoolSize addWorker并不是直接创建线程，而是Worker对象，传入的Runnable任务对象作为其属性。 代码 @2 处 workers就是线程池的集合： /** * Set containing all worker threads in pool. Accessed only when holding mainLock. * * 译：一个包含线程池内所有工作线程的集合，仅在持有mainLock时可访问 */ private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); Worker就是实际线程池中的“线程”： private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread; // 当前worker实际运行的线程 Runnable firstTask; // 初始化的任务 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 创建线程，注意此处将worker作为Thread的构造参数 } public void run() { runWorker(this); } } Worker作为Runnable实现类，并拥有一个Thread属性 从其构造器还可以发现，thread属性的target又是当前worker对象 上面addWorker方法的 @3 处显示Worker创建后会启动Worker内置的Thread对象, 这意味着，thread.start() 实际会调用worker.run(),而run内部又是调用runWorker方法，其源码为： final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { // @4 无限循环获取任务 ... try { beforeExecute(wt, task); // @5 protected修饰的空方法，可用于线程池子类扩展 Throwable thrown = null; try { task.run(); // @6 调用实际Runnable实例的run方法 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); // @7 protected修饰的空方法，可用于线程池子类扩展 } } finally { task = null; // @8 每个task执行完成后，置空变量，下次再拿到一个新的task w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } @5 、@7处是空的protected方法，很明显是用来提供子类扩展的 @4 、@6、@8 处揭露了Worker在启动之后，会无限循环通过getTask获取Runnable任务，并调用任务的run()方法。 getTask() 方法源码： private Runnable getTask() { ...(省略若干行状态校验代码) try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } 可以到，实际是调用队列的poll或take来获取任务，这两个方法都是阻塞的，没有取到任务就会阻塞住，区别只是pool有超时时间。 综上，可以总结出 addWorker方法作用：创建线程Worker对象，并启动线程，线程内会无限循环的从队列中带阻塞的获取执行任务。 再回到execute方法： public void execute(Runnable command) { ... int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // @1 if (addWorker(command, true)) // @2 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // @3 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // @4 reject(command); else if (workerCountOf(recheck) == 0) // @5 addWorker(null, false); } else if (!addWorker(command, false)) // @6 reject(command); } @1：存活Worker数量是否小于corePoolSize。 @2：创建并启动Worker，上限为corePoolSize，Worker执行完初始化时分配任务后，无限循环从队列有阻塞的获取任务。 @3：存活Worker数量 = corePoolSize，线程池状态为Running（可接受新任务），且将新任务加入队列. @4：二次检查线程池状态，非Runing时，将加入的任务移除。 @5：二次检查线程池状态依然为Running，且存活Worker数量 = 0（因为corePoolSize可能为0），创建并启动Worker，上限为MaxPoolSize @6: 线程池状态部位Running或队列添加失败（队列满），创建并启动Worker（内部有状态校验），上限为MaxPoolSize 结论 基于以上分析，发现误区有两点： 线程池添加超出corePoolSize线程时，依据活跃线程数量来判断，这个活跃线程和当前处理的任务数量没有任何关系，上面说到理解成存活Worker数量是比较贴切的，而Worker启动后是无限循环读取队列的，所以 活跃的线程数 = 存活线程数 != 活跃（处理中）任务数。 任务提交给线程池，如果线程池有空闲线程，那么新加入的任务是能够被空闲线程（未处理任务的线程）处理的，但容易先入为主的认为，任务直接分配给空闲线程的，实际除了创建线程时给的任务，其它的任务是先放到队列中的，线程和队列是一个生产者消费者模型。 案例复盘： 当有3个outter线程处理时，inner线程池累计创建了9（corePoolSize）个Worker 后续任务到达时，任务将直接入inner队列，由于队列大小为1，线程从队列消费任务及时性无法保证 ① ，队列入队可能失败 队列入队失败时，inner继续创建线程，知道总数量为12（maxPoolSize） 后续任务到达，再次入队，同步骤 2，此时一旦入队失败，就会触发reject ① 事实上，线程调用 queue.take() 和 外部调用queue.offer()间没有任何关联的，线程之间是由竞争的，无法保证及时消费队列中任务是可能的。 验证 既然已经明白可能的误区，针对误区简化案例即可 static class MyLinkedBlockingQueue&lt;E&gt; extends LinkedBlockingQueue&lt;E&gt; { public MyLinkedBlockingQueue(int capacity) { super(capacity); } @Override public boolean offer(E o) { System.out.println(&quot;任务加入，当前队列数：&quot; + this.size()); return super.offer(o); } } public static void main(String[] args) throws InterruptedException { BlockingQueue queue = new MyLinkedBlockingQueue&lt;&gt;(1); // 3个线程的线程池 ThreadPoolExecutor taskPoolExecutor = new ThreadPoolExecutor(3, 3, 30, TimeUnit.SECONDS, queue); // 先将线程池拉满 for (int i = 0; i &lt; 3; i++) { final int finalI = i; taskPoolExecutor.execute(() -&gt; { logger.info(&quot;{}&quot;, finalI); }); } // 等待全部任务执行完 Thread.sleep(1000); // 再次执行任务，发现每一个任务都触发加入队列操作。 for (int i = 10; i &lt; 12; i++) { // @1 for (int i = 10; i &lt; 15; i++) { // @2 final int finalI = i; taskPoolExecutor.execute(() -&gt; { // @3 /* try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } */ System.out.println(finalI); } } 执行结果： 0 2 1 任务加入，当前队列数：0 任务加入，当前队列数：1 10 11 可以看到，线程池满了之后，哪怕线程全部空闲，新的任务也是放到队列中。 将上述代码中的@1 换成 @2 ，去掉 @3处的注释，使得每个任务耗时更久且要添加任务数大于corePoolSize，这样队列就会来不及出列从而触发reject。 执行结果： 2 0 1 任务加入，当前队列数：0 任务加入，当前队列数：1 任务加入，当前队列数：0 任务加入，当前队列数：1 任务加入，当前队列数：1 Exception in thread &quot;main&quot; java.util.concurrent.RejectedExecutionException: Task com.review.string.Demo8$$Lambda$2/249515771@2f7a2457 rejected from java.util.concurrent.ThreadPoolExecutor@566776ad[Running, pool size = 3, active threads = 3, queued tasks = 1, completed tasks = 3] 完美验证！ 总结 ThreadPoolExecutor其实并不神秘，就是一个生产消费模型,特殊点： 在线程池到达corePoolSize大小时，任务是直接分配给新线程的。 在线程池到达corePoolSize大小且添加队列满,任务可以直接分配给新线程，直到达到maxPoolSize大小，相当于生产者生产的事件满了之后，给消费者一次扩容的机会。 其它时候队列未满时，添加任务相当于生产事件到队列，线程从队列消费事件，当队列满时，触发reject。 所以实际配置中，除了线程池大小，队列大小也要参考并发量合理设置。 ","link":"https://season8.github.io/post/threadpoolexecutor/"},{"title":"HTTP 进化简史","content":"八股八股HTTP基础 本文主要概括以下内容： 什么是HTTP。 HTTP 和 TCP 关系。 HTTP 的效率受哪些因素影响。 HTTP 主要版本极其特性。 什么是HTTPS，和HTTP的区别是什么。 什么是HTTP协议 超文本传输协议（HTTP：Hypertext Transport Protocol）是建立在TCP协议上的应用层协议，客户端和服务端通过建立连接，发送请求和响应报文，完成数据请求和响应。 白话：HTTP 定义了数据的格式、数据处理方式 以及 连接的使用方式，而连接的建立和释放是由TCP协议控制的。 HTTP 和 TCP 关系 TCP 是传输层协议，建立TCP连接需要三次握手，释放连接需要四次挥手，因此，TCP是可靠的连接，TCP连接是有状态的，只要保持连接不释放，可以传输多组数据。 HTTP是应用层协议，约定了请求行格式和响应格式，约定了关键字，在HTTP1.0中，一个HTTP响应结束后会关闭TCP连接，从而产生了无状态的特性。 影响HTTP请求的因素 带宽 浏览器阻塞造成的延迟。浏览器对同一个域名同时只能有4个连接（不同内核可能不同），超过的连接被阻塞。 DNS 解析造成的延迟。浏览器只有知道请求的服务器ip后才会发起请求。 建立连接造成的延迟。HTTP请求连接需要3次握手。 关闭连接造成的延迟。HTTP连接关闭需要4次挥手，当浏览器需要创建多个连接时，关闭连接耗时会造成后续请求阻塞时间的延长。 HTTP主要版本极其特性 HTTP1.0 无连接/短连接，一个连接只处理一个请求，每一次请求都要经历创建、关闭连接。 无状态，对于事务处理没有记忆能力，后续请求如果要用到前序请求的数据、状态，则必须重传这部分数据和状态。 请求不含主机名（hostname）,HTTP1.0中认为每台服务器都绑定一个唯一的IP地址。 灵活的数据类型，通过请求头Content-Type字段可以支持多种数据结构。 简单快速：请求只需要url、method、param/post-data即可完成请求，协议简单易用，响应迅速。 问：怎么解决无状态下状态持久化问题？ 答：客户端方案：cookie、localStorage，服务端方案：session HTTP1.1 新增缓存字段 和 错误状态码 Host头处理,增加hostname,解决一台机器多个虚拟主机的情况。 支持长连接，一个TCP连接可以多次发送HTTP请求，默认开启Connection： keep-alive HTTP2.0 [科普]TCP慢启动：TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度 多路复用。利用二进制分栈技术，实现单连接多资源，减少服务端的链接压力,内存占用更少,连接吞吐量更大；减少TCP 慢启动时间，提高传输的速度。 首部压缩。浏览器和服务端都可以向动态字典中添加键值对，之后这个键值对就可以使用一个字符表示。 维护一份相同的静态字典（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合； 维护一份相同的动态字典（Dynamic Table），可以动态的添加内容； 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）； 服务器推送，服务器知道浏览器需要加载附加资源时，在响应第一个请求之后，可以主动推送附加资源，充分利用网络空闲资源。 HTTPS和HTTP 超文本传输安全协议（HTTPS: Hypertext Transfer Protocol Secure：）是基于HTTP协议的安全通信协议，加密方式是 SSL/TLS。 HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。 HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式： TCP 三次同步握手 客户端验证服务器数字证书 DH 算法协商对称加密算法的密钥、hash 算法的密钥 SSL 安全加密隧道协商完成 网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。 ","link":"https://season8.github.io/post/http/"},{"title":"久违的开始","content":"👏 欢迎来到我的小栈 ！ ✍️ 小栈 并不限于技术分享。 Github 小栈 主页 🤔总是想太多，一来没有拿得出手的吊炸天的技术，二来没有敢说精通的技能，三来写完觉得写的不好。 😵纠结就是拖延的开始，所以辗转一番，发现还是不能拘泥于内容、深度。明明就是一个自嗨的东西就不要总是端着一副写点什么给科学家看了学去好拯救世界的心态。 😁这样就豁然开朗了，没人看是常态，能写出来的东西，首先要自我满足，倘若有他人看了，能再提供一份喜闻乐见都是好的。 写什么👇 📝 技术总结，主要是Java 后端的一些东西，八股肯定是会八股的🤣 💻 站点、小工具等软件使用分享，没用但很舒服的瞎折腾。 🏡 家庭、育儿等生活方式以及一些思考。 📋 怎么写 金字塔法则 🌟 在工作中我接触了金字塔法则，这是一种用于提高书面以及口头表述能力的方法。作为技术人员，这个方法用于写作是再合适不过了。 1.金字塔法则的基本结构是： 1）结论先行； 2）以上统下； 3）归类分组； 4）逻辑递进。 2.基本规则是： 1）先重要后次要； 2）先总结后具体； 3）先框架后细节； 4）先结论后原因； 5）先结果后过程； 6）先结论后论据。 3.具体做法： 1）自上而下表达、自下而上思考； 2）纵向总结概括、横向归纳分组； 3）序言讲故事、标题提炼精华。 5W2H分析法 🌟 这是从别的作者那里学到的技巧，这应该是更适合于技术人员的写作三板斧了。 WHAT——目的、概念、原理是什么？ WHY——为什么要做？ WHO——由谁或者说哪个角色来做？ WHEN——什么时间做？什么时机最适宜？ WHERE——何处？在哪里做？ HOW ——怎么做？如何提高效率？如何实施？方法是什么？ HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？ 关于辞藻 尝试过对刚写的文章进行辞藻加工，实在难以为继，我的幽默用不到文章上，所以，先表达清楚，写得多了，应该会有提高。 最后 少BB，开始吧！ 😘 Enjoy Myself~ ","link":"https://season8.github.io/post/hello/"}]}