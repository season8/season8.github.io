{"posts":[{"title":"重新认识 ThreadPoolExecutor","content":"❓ 更深入的理解ThreadPoolExecutor原理，纠正想当然的理解误区 一个事故引发的拷问 或许这篇文章可以起名更惊悚一点，叫做：《不合理的线程池配置酿成的血案。。》。 事情要从一个造成生产事故的案例说起： 同事开发了一个kafka消费者程序，并发消费消息： 使用Semaphore控制每次并发处理m个消息 每一个消息处理后都会生成 n 个任务，为了加快单个消息的处理速率，子任务也采用了并发的方式执行（消息和子任务线程池是分开的） 外层消息处理等待所有子任务执行完成才算完成。 整个模型设计的目标很明确，那就是每次能并发处理m个消息，m*n个子任务，每组子任务全部执行完毕后才会开始下一组。 但真实的情况是，发布线上后，子任务线程池大面积触发Reject，导致消息处理几乎瘫痪，下游出现数据缺失以及高延迟。 在协同检查后，我也认为这个模型设计十分精确，不会存在子任务超量的情况。 问题复现 由于该模型在本地测试并没有触发异常，考虑到是数据量级的原因，我基于现有模型，缩放了任务量级和配置，简化出了以下模型并复现了问题： 假设有多个消费事件组，要求同时最多三个事件组异步消费，而每个事件组由3个子事件组成，子事件同样使用异步消费。 public static void main(String[] args) throws InterruptedException { // @1 创建外部消费组线程池，固定大小3，队列197，一共200个消费组 ThreadPoolExecutor outter = new ThreadPoolExecutor(3, 3, 30, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(197)); // @2 创建内部事件处理线程池，core=9，max=12 ，队列长度为1。 ThreadPoolExecutor inner = new ThreadPoolExecutor(9, 12, 30, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(1)); //2 for (int i = 0; i &lt; 200; i++) { int group = i; // @3 消费组异步处理，由于outter固定大小为3，首次只有三个消费组消费事件。 outter.execute(() -&gt; { System.out.println(&quot;开始第&quot; + group + &quot; 组消费&quot;); CountDownLatch countDownLatch = new CountDownLatch(3); for (int j = 0; j &lt; 3; j++) { int task = j; // @4 3个事件异步消费， inner.execute(() -&gt; { System.out.println(group + &quot;组消费数据:&quot; + task); countDownLatch.countDown(); }); } // @5 outter线程等待三个inner线程结束，当前组才消费完成 try { countDownLatch.await(3, TimeUnit.SECONDS); System.out.println(&quot;第&quot; + group + &quot; 消费完成&quot;); } catch (InterruptedException e) { e.printStackTrace(); } }); } } 实现该模型的基本策略： 利用CountDownLatch保证outter线程在对应的三个inner线程执行完之后才执行完毕，即：保证批次执行； 利用outter固定线程池=3，保证每次最多只有三个outter线程执行； 同理，inner每次只能有 3（outter执行数量）* 3（事件数量） = 9 个线程在执行。所以理论上，inner的max=12是用不上的，队列也用不上。 执行结果： ... Exception in thread &quot;pool-1-thread-1&quot; Exception in thread &quot;pool-1-thread-3&quot; Exception in thread &quot;pool-1-thread-2&quot; java.util.concurrent.RejectedExecutionException: Task com.review.string.Demo7$$Lambda$2/1186543288@67dad061 rejected from java.util.concurrent.ThreadPoolExecutor@67aa5a39[Running, pool size = 12, active threads = 3, queued tasks = 0, completed tasks = 14] ... 可发发现，子任务线程池容量竟然扩充到了12，达到了最大容量，按前面所想，子任务数量应该是控制在3*3=9个才对。 分析 猜测：countDownLatch没有控制住 假设实际执行的outter active数量 * 3 &gt; 实际inner active线程数，从而导致inner线程达到最大线程数。 这里countDownLatch数量配置都是对的，增加inner消费处理时间，发现在reject前，outter线程都是在组内inner全部执行完才完成，没有失控的迹象。 如果你的猜测是这个，我觉得你可以多多使用juc中的工具，这个模型中，countDownLatch和线程池的配合使用是没有问题的。 猜测：线程调度的问题 假设outter线程o1执行完，o2、o3还在执行，开始执行o4，此时如果o1组内的inner线程 i1、i2、i3至少一个还没有及时归还到线程池中，这样o4组消费就会创建新的线程使得线程数&gt;core,持续几轮，线程池撑满从而触发reject。 这个猜测并无根据，但依然可以验证一下: countDownLatch.await(); TimeUnit.SECONDS.sleep(1); // outter强制等待inner结束 执行，仍然reject,可以排除该猜想 猜想都没有实际根据且都可以被证伪，我突然有些恐慌，比起在小同事这里翻车，我发现我根本没有理解线程池这件事才是超恐怖的。 我此时所认知的线程池： 活跃线程数 &lt; corePoolSize 时，直接创建线程来执行任务。 活跃线程数 = corePoolSize 时，任务添加到队列，等待空闲线程处理。 队列满时，直接创建线程来执行任务。 活跃线程数 = maxPoolSize，继续添加任务，触发reject。 通过后续的研究，我才发现，这几条简短的概括，并不能说错误，但是因为简短，说明有些概念并不明确，或者很模糊，正是这种似是而非的认识，导致我对线程池的具体细节都是想当然。 终极武器，看源码实现： 直接从核心方法 execute 入手： public void execute(Runnable command) { ... int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // @1 if (addWorker(command, true)) // @2 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // @3 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // @4 reject(command); else if (workerCountOf(recheck) == 0) // @5 addWorker(null, false); } else if (!addWorker(command, false)) // @6 reject(command); } 这里主要有6个不太明确作用的方法，我们逐个分析： workerCountOf isRunning addWorker workQueue.offer(command) remove(command) reject(command) workerCountOf &amp; isRunning 了解这两个方法是ThreadPoolExecutor类的基本方法，我们直接看ThreadPoolExecutor的源码： public class ThreadPoolExecutor extends AbstractExecutorService { /** * The main pool control state, ctl, is an atomic integer packing two conceptual fields * workerCount, indicating the effective number of threads * runState, indicating whether running, shutting down etc * * 译：状态ctl是一个包装了两个概念字段原子整数: * workerCount 指示有效的线程数, * runState 指示是否运行，关闭等 * ... * * The workerCount is the number of workers that have been * permitted to start and not permitted to stop. The value may be * transiently different from the actual number of live threads, * for example when a ThreadFactory fails to create a thread when * asked, and when exiting threads are still performing * bookkeeping before terminating. The user-visible pool size is * reported as the current size of the workers set. * * 译：workerCount是【已被允许启动且未被允许停止】的worder(即线程)数量。 * 该值可能与实际的活动线程数暂时不同：线程池创建线程时失败但又未完全注销， * 此时workerCount 可能会小于线程池实际大小。 * * 【已被允许启动且未被允许停止】 先简单理解为存活线程比较好理解 * ... * * The runState provides the main lifecycle control, taking on values: * * RUNNING: Accept new tasks and process queued tasks * SHUTDOWN: Don't accept new tasks, but process queued tasks * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * TIDYING: All tasks have terminated, workerCount is zero, * the thread transitioning to state TIDYING * will run the terminated() hook method * TERMINATED: terminated() has completed * * 译：runState提供线程池生命周期的控制，有以下状态值： * RUNNING：可接受新任务，可处理队列中的任务 * SHUTDOWN：不接受新任务，但可以处理队列中的任务 * STOP：不接受新任务，不处理队列中任务，并中断处理中的任务 * TIDYING：所有任务都已终止，workerCount(存活的线程数量)为0,往该状态过渡的线程将执行terminated() * TERMINATED: terminated()方法结束，相当于TIDYING的终态。 * ... * * 后面还有部分注释，讲的是runState 各个状态之间转换条件，不作列出，有兴趣可自研 * / // 状态和线程数集合包装字段ctl。 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static int runStateOf(int c) { return c &amp; ~CAPACITY; } // 从 ctl 拆解出 runState private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 从 crl 拆解出 workerCount private static int ctlOf(int rs, int wc) { return rs | wc; } // 将 workerCount 和 runState 包装为 ctl ... private static boolean isRunning(int c) { return c &lt; SHUTDOWN;} // 当前线程池状态，是否处于Running状态 ctl包装和解析 runState 与 workCount 的算法并未理解，但并不影响理解其概念。 workerCountOf方法 ：获取存活线程数量 isRunning方法 ：判断线程池状态是否处于Running(Running状态时线程池可接受新任务) addWorker private boolean addWorker(Runnable firstTask, boolean core) { //...（略掉一些状态校验） int wc = workerCountOf(c); // 线程池实际容量（存活线程数量） if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // @1 判断是否达到容量上限 //...（略掉一些状态校验） w = new Worker(firstTask); // @1 根据任务创建Worker对象 final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); // @2 将worker对象添加到集合workers中 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); // @3 添加成功，启动worker内置线程 workerStarted = true; } } //... } addWorker在execute方法中有两处调用，区别是参数core传值不同，从源码可以看出是判断当前线程池容量上限是CorePoolSize还是MaxPoolSize addWorker并不是直接创建线程，而是Worker对象，传入的Runnable任务对象作为其属性。 代码 @2 处 workers就是线程池的集合： /** * Set containing all worker threads in pool. Accessed only when holding mainLock. * * 译：一个包含线程池内所有工作线程的集合，仅在持有mainLock时可访问 */ private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); Worker就是实际线程池中的“线程”： private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread; // 当前worker实际运行的线程 Runnable firstTask; // 初始化的任务 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 创建线程，注意此处将worker作为Thread的构造参数 } public void run() { runWorker(this); } } Worker作为Runnable实现类，并拥有一个Thread属性 从其构造器还可以发现，thread属性的target又是当前worker对象 上面addWorker方法的 @3 处显示Worker创建后会启动Worker内置的Thread对象, 这意味着，thread.start() 实际会调用worker.run(),而run内部又是调用runWorker方法，其源码为： final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { // @4 无限循环获取任务 ... try { beforeExecute(wt, task); // @5 protected修饰的空方法，可用于线程池子类扩展 Throwable thrown = null; try { task.run(); // @6 调用实际Runnable实例的run方法 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); // @7 protected修饰的空方法，可用于线程池子类扩展 } } finally { task = null; // @8 每个task执行完成后，置空变量，下次再拿到一个新的task w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } @5 、@7处是空的protected方法，很明显是用来提供子类扩展的 @4 、@6、@8 处揭露了Worker在启动之后，会无限循环通过getTask获取Runnable任务，并调用任务的run()方法。 getTask() 方法源码： private Runnable getTask() { ...(省略若干行状态校验代码) try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } 可以到，实际是调用队列的poll或take来获取任务，这两个方法都是阻塞的，没有取到任务就会阻塞住，区别只是pool有超时时间。 综上，可以总结出 addWorker方法作用：创建线程Worker对象，并启动线程，线程内会无限循环的从队列中带阻塞的获取执行任务。 再回到execute方法： public void execute(Runnable command) { ... int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // @1 if (addWorker(command, true)) // @2 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // @3 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // @4 reject(command); else if (workerCountOf(recheck) == 0) // @5 addWorker(null, false); } else if (!addWorker(command, false)) // @6 reject(command); } @1：存活Worker数量是否小于corePoolSize。 @2：创建并启动Worker，上限为corePoolSize，Worker执行完初始化时分配任务后，无限循环从队列有阻塞的获取任务。 @3：存活Worker数量 = corePoolSize，线程池状态为Running（可接受新任务），且将新任务加入队列. @4：二次检查线程池状态，非Runing时，将加入的任务移除。 @5：二次检查线程池状态依然为Running，且存活Worker数量 = 0（因为corePoolSize可能为0），创建并启动Worker，上限为MaxPoolSize @6: 线程池状态部位Running或队列添加失败（队列满），创建并启动Worker（内部有状态校验），上限为MaxPoolSize 结论 基于以上分析，发现误区有两点： 线程池添加超出corePoolSize线程时，依据活跃线程数量来判断，这个活跃线程和当前处理的任务数量没有任何关系，上面说到理解成存活Worker数量是比较贴切的，而Worker启动后是无限循环读取队列的，所以 活跃的线程数 = 存活线程数 != 活跃（处理中）任务数。 任务提交给线程池，如果线程池有空闲线程，那么新加入的任务是能够被空闲线程（未处理任务的线程）处理的，但容易先入为主的认为，任务直接分配给空闲线程的，实际除了创建线程时给的任务，其它的任务是先放到队列中的，线程和队列是一个生产者消费者模型。 案例复盘： 当有3个outter线程处理时，inner线程池累计创建了9（corePoolSize）个Worker 后续任务到达时，任务将直接入inner队列，由于队列大小为1，线程从队列消费任务及时性无法保证 ① ，队列入队可能失败 队列入队失败时，inner继续创建线程，知道总数量为12（maxPoolSize） 后续任务到达，再次入队，同步骤 2，此时一旦入队失败，就会触发reject ① 事实上，线程调用 queue.take() 和 外部调用queue.offer()间没有任何关联的，线程之间是由竞争的，无法保证及时消费队列中任务是可能的。 验证 既然已经明白可能的误区，针对误区简化案例即可 static class MyLinkedBlockingQueue&lt;E&gt; extends LinkedBlockingQueue&lt;E&gt; { public MyLinkedBlockingQueue(int capacity) { super(capacity); } @Override public boolean offer(E o) { System.out.println(&quot;任务加入，当前队列数：&quot; + this.size()); return super.offer(o); } } public static void main(String[] args) throws InterruptedException { BlockingQueue queue = new MyLinkedBlockingQueue&lt;&gt;(1); // 3个线程的线程池 ThreadPoolExecutor taskPoolExecutor = new ThreadPoolExecutor(3, 3, 30, TimeUnit.SECONDS, queue); // 先将线程池拉满 for (int i = 0; i &lt; 3; i++) { final int finalI = i; taskPoolExecutor.execute(() -&gt; { logger.info(&quot;{}&quot;, finalI); }); } // 等待全部任务执行完 Thread.sleep(1000); // 再次执行任务，发现每一个任务都触发加入队列操作。 for (int i = 10; i &lt; 12; i++) { // @1 for (int i = 10; i &lt; 15; i++) { // @2 final int finalI = i; taskPoolExecutor.execute(() -&gt; { // @3 /* try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } */ System.out.println(finalI); } } 执行结果： 0 2 1 任务加入，当前队列数：0 任务加入，当前队列数：1 10 11 可以看到，线程池满了之后，哪怕线程全部空闲，新的任务也是放到队列中。 将上述代码中的@1 换成 @2 ，去掉 @3处的注释，使得每个任务耗时更久且要添加任务数大于corePoolSize，这样队列就会来不及出列从而触发reject。 执行结果： 2 0 1 任务加入，当前队列数：0 任务加入，当前队列数：1 任务加入，当前队列数：0 任务加入，当前队列数：1 任务加入，当前队列数：1 Exception in thread &quot;main&quot; java.util.concurrent.RejectedExecutionException: Task com.review.string.Demo8$$Lambda$2/249515771@2f7a2457 rejected from java.util.concurrent.ThreadPoolExecutor@566776ad[Running, pool size = 3, active threads = 3, queued tasks = 1, completed tasks = 3] 完美验证！ 总结 ThreadPoolExecutor其实并不神秘，就是一个生产消费模型,特殊点： 在线程池到达corePoolSize大小时，任务是直接分配给新线程的。 在线程池到达corePoolSize大小且添加队列满,任务可以直接分配给新线程，直到达到maxPoolSize大小，相当于生产者生产的事件满了之后，给消费者一次扩容的机会。 其它时候队列未满时，添加任务相当于生产事件到队列，线程从队列消费事件，当队列满时，触发reject。 所以实际配置中，除了线程池大小，队列大小也要参考并发量合理设置。 ","link":"https://season8.github.io/post/threadpoolexecutor/"},{"title":"HTTP 进化简史","content":"八股八股HTTP基础 本文主要概括以下内容： 什么是HTTP。 HTTP 和 TCP 关系。 HTTP 的效率受哪些因素影响。 HTTP 主要版本极其特性。 什么是HTTPS，和HTTP的区别是什么。 什么是HTTP协议 超文本传输协议（HTTP：Hypertext Transport Protocol）是建立在TCP协议上的应用层协议，客户端和服务端通过建立连接，发送请求和响应报文，完成数据请求和响应。 白话：HTTP 定义了数据的格式、数据处理方式 以及 连接的使用方式，而连接的建立和释放是由TCP协议控制的。 HTTP 和 TCP 关系 TCP 是传输层协议，建立TCP连接需要三次握手，释放连接需要四次挥手，因此，TCP是可靠的连接，TCP连接是有状态的，只要保持连接不释放，可以传输多组数据。 HTTP是应用层协议，约定了请求行格式和响应格式，约定了关键字，在HTTP1.0中，一个HTTP响应结束后会关闭TCP连接，从而产生了无状态的特性。 影响HTTP请求的因素 带宽 浏览器阻塞造成的延迟。浏览器对同一个域名同时只能有4个连接（不同内核可能不同），超过的连接被阻塞。 DNS 解析造成的延迟。浏览器只有知道请求的服务器ip后才会发起请求。 建立连接造成的延迟。HTTP请求连接需要3次握手。 关闭连接造成的延迟。HTTP连接关闭需要4次挥手，当浏览器需要创建多个连接时，关闭连接耗时会造成后续请求阻塞时间的延长。 HTTP主要版本极其特性 HTTP1.0 无连接/短连接，一个连接只处理一个请求，每一次请求都要经历创建、关闭连接。 无状态，对于事务处理没有记忆能力，后续请求如果要用到前序请求的数据、状态，则必须重传这部分数据和状态。 请求不含主机名（hostname）,HTTP1.0中认为每台服务器都绑定一个唯一的IP地址。 灵活的数据类型，通过请求头Content-Type字段可以支持多种数据结构。 简单快速：请求只需要url、method、param/post-data即可完成请求，协议简单易用，响应迅速。 问：怎么解决无状态下状态持久化问题？ 答：客户端方案：cookie、localStorage，服务端方案：session HTTP1.1 新增缓存字段 和 错误状态码 Host头处理,增加hostname,解决一台机器多个虚拟主机的情况。 支持长连接，一个TCP连接可以多次发送HTTP请求，默认开启Connection： keep-alive HTTP2.0 [科普]TCP慢启动：TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度 多路复用。利用二进制分栈技术，实现单连接多资源，减少服务端的链接压力,内存占用更少,连接吞吐量更大；减少TCP 慢启动时间，提高传输的速度。 首部压缩。浏览器和服务端都可以向动态字典中添加键值对，之后这个键值对就可以使用一个字符表示。 维护一份相同的静态字典（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合； 维护一份相同的动态字典（Dynamic Table），可以动态的添加内容； 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）； 服务器推送，服务器知道浏览器需要加载附加资源时，在响应第一个请求之后，可以主动推送附加资源，充分利用网络空闲资源。 HTTPS和HTTP 超文本传输安全协议（HTTPS: Hypertext Transfer Protocol Secure：）是基于HTTP协议的安全通信协议，加密方式是 SSL/TLS。 HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。 HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式： TCP 三次同步握手 客户端验证服务器数字证书 DH 算法协商对称加密算法的密钥、hash 算法的密钥 SSL 安全加密隧道协商完成 网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。 ","link":"https://season8.github.io/post/http/"},{"title":"久违的开始","content":"👏 欢迎来到我的小栈 ！ ✍️ 小栈 并不限于技术分享。 Github 小栈 主页 🤔总是想太多，一来没有拿得出手的吊炸天的技术，二来没有敢说精通的技能，三来写完觉得写的不好。 😵纠结就是拖延的开始，所以辗转一番，发现还是不能拘泥于内容、深度。明明就是一个自嗨的东西就不要总是端着一副写点什么给科学家看了学去好拯救世界的心态。 😁这样就豁然开朗了，没人看是常态，能写出来的东西，首先要自我满足，倘若有他人看了，能再提供一份喜闻乐见都是好的。 写什么👇 📝 技术总结，主要是Java 后端的一些东西，八股肯定是会八股的🤣 💻 站点、小工具等软件使用分享，没用但很舒服的瞎折腾。 🏡 家庭、育儿等生活方式以及一些思考。 📋 怎么写 金字塔法则 🌟 在工作中我接触了金字塔法则，这是一种用于提高书面以及口头表述能力的方法。作为技术人员，这个方法用于写作是再合适不过了。 1.金字塔法则的基本结构是： 1）结论先行； 2）以上统下； 3）归类分组； 4）逻辑递进。 2.基本规则是： 1）先重要后次要； 2）先总结后具体； 3）先框架后细节； 4）先结论后原因； 5）先结果后过程； 6）先结论后论据。 3.具体做法： 1）自上而下表达、自下而上思考； 2）纵向总结概括、横向归纳分组； 3）序言讲故事、标题提炼精华。 5W2H分析法 🌟 这是从别的作者那里学到的技巧，这应该是更适合于技术人员的写作三板斧了。 WHAT——目的、概念、原理是什么？ WHY——为什么要做？ WHO——由谁或者说哪个角色来做？ WHEN——什么时间做？什么时机最适宜？ WHERE——何处？在哪里做？ HOW ——怎么做？如何提高效率？如何实施？方法是什么？ HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？ 关于辞藻 尝试过对刚写的文章进行辞藻加工，实在难以为继，我的幽默用不到文章上，所以，先表达清楚，写得多了，应该会有提高。 最后 少BB，开始吧！ 😘 Enjoy Myself~ ","link":"https://season8.github.io/post/hello/"}]}